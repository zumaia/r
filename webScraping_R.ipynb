{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webScraping_R.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPI5sHrUBCkkr0m5PUIpZF4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zumaia/r/blob/master/webScraping_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj7L_W-25AjV",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial de web scraping en R\n",
        "\n",
        "\n",
        "Ref.:  https://towardsdatascience.com/web-scraping-tutorial-in-r-5e71fd107f32\n",
        "\n",
        "Hace un par de días, Kevin Markham de la Escuela de Datos, publicó un bonito tutorial sobre web scraping usando 16 líneas de código Python.\n",
        "\n",
        "El web scraping de las mentiras del Presidente en 16 líneas de Python\n",
        "Nota: Este tutorial está disponible como un cuaderno de Jupyter, y el conjunto de datos de las mentiras está disponible como un archivo CSV,...www.dataschool.io *texto en cursiva\n",
        "http://www.dataschool.io/python-web-scraping-of-president-trumps-lies/\n",
        "*\n",
        "\n",
        "El tutorial es simple y muy bien hecho. Le recomiendo encarecidamente que le eche un vistazo. De hecho, tal tutorial me motivó a replicar los resultados pero esta vez usando R. Con el permiso de Kevin, usaré un diseño similar al de su entrada en el blog. También usaré el mismo sitio web sobre un artículo de opinión llamado Mentiras de Trump. Esto debería facilitar cualquier comparación entre los dos enfoques.\n",
        "\n",
        "## Examinando el artículo del New York Times\n",
        "\n",
        "Para una buena descripción del artículo con el que trabajaremos, te animo a que le eches un vistazo al tutorial de Kevin. En resumen, los datos que nos interesan consisten en un registro de mentiras, cada uno con 4 partes:\n",
        "\n",
        "    La fecha de la mentira\n",
        "    La mentira en sí misma\n",
        "    Una explicación de por qué era una mentira\n",
        "    Un URL para un artículo que apoye la explicación (incrustado en el texto)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTHXu1fb5T9d",
        "colab_type": "text"
      },
      "source": [
        "## Leyendo la página web en R\n",
        "\n",
        "Para leer la página web en R, podemos usar el paquete rvest, hecho por el gurú de R Hadley Wickham. Este paquete está inspirado en bibliotecas como Beautiful Soup, para facilitar el raspado de datos de páginas web html. La primera función importante a usar es read_html(), que devuelve un documento XML que contiene toda la información de la página web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trBWwonE4gS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e4747241-9042-4bbc-e8e7-6fa4cba539ba"
      },
      "source": [
        "library(rvest)\n",
        "webpage <- read_html(\"https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html\")\n",
        "webpage"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading required package: xml2\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{html_document}\n",
              "<html lang=\"en\" class=\"no-js page-interactive section-opinion page-theme-standard tone-opinion page-interactive-default limit-small layout-xlarge app-interactive\" itemid=\"https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html\" itemtype=\"http://schema.org/NewsArticle\" itemscope=\"\" xmlns:og=\"http://opengraphprotocol.org/schema/\">\n",
              "[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n",
              "[2] <body>\\n<style>\\n.lt-ie10 .messenger.suggestions {\\n  display: block !imp ..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTkGbxiR5njC",
        "colab_type": "text"
      },
      "source": [
        "Recoger todos los registros\n",
        "\n",
        "Como se explica en el tutorial de Kevin, cada registro tiene la siguiente estructura en el código HTML:\n",
        "\n",
        "<span class=\"short-desc\"><strong> DATE </strong> LIE <span class=\"short-truth\"><a href=\"URL\"> EXPLANATION </a></span></span>\n",
        "\n",
        "Por lo tanto, para recoger todas las mentiras, necesitamos identificar todas las etiquetas <span> que pertenecen a class=\"shortdesc\". La función que nos ayudará a hacerlo es html_nodes(). Esta función requiere el documento XML que hemos leído y los nodos que queremos seleccionar. Para esto último, se recomienda utilizar el SelectorGadget, una herramienta de código abierto que facilita la generación y el descubrimiento de los selectores de CSS. Usando dicha herramienta, encontramos que todas las mentiras pueden ser seleccionadas usando el selector \".short-desc\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6ryr45P4rE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "85612a3d-cfe2-4f1e-cce5-20e18354449c"
      },
      "source": [
        "results <- webpage %>% html_nodes(\".short-desc\")\n",
        "results"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{xml_nodeset (180)}\n",
              " [1] <span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Ira ...\n",
              " [2] <span class=\"short-desc\"><strong>Jan. 21 </strong>“A reporter for Time m ...\n",
              " [3] <span class=\"short-desc\"><strong>Jan. 23 </strong>“Between 3 million and ...\n",
              " [4] <span class=\"short-desc\"><strong>Jan. 25 </strong>“Now, the audience was ...\n",
              " [5] <span class=\"short-desc\"><strong>Jan. 25 </strong>“Take a look at the Pe ...\n",
              " [6] <span class=\"short-desc\"><strong>Jan. 25 </strong>“You had millions of p ...\n",
              " [7] <span class=\"short-desc\"><strong>Jan. 25 </strong>“So, look, when Presid ...\n",
              " [8] <span class=\"short-desc\"><strong>Jan. 26 </strong>“We've taken in tens o ...\n",
              " [9] <span class=\"short-desc\"><strong>Jan. 26 </strong>“I cut off hundreds of ...\n",
              "[10] <span class=\"short-desc\"><strong>Jan. 28 </strong>“The coverage about me ...\n",
              "[11] <span class=\"short-desc\"><strong>Jan. 29 </strong>“The Cuban-Americans,  ...\n",
              "[12] <span class=\"short-desc\"><strong>Jan. 30 </strong>“Only 109 people out o ...\n",
              "[13] <span class=\"short-desc\"><strong>Feb. 3 </strong>“Professional anarchist ...\n",
              "[14] <span class=\"short-desc\"><strong>Feb. 4 </strong>“After being forced to  ...\n",
              "[15] <span class=\"short-desc\"><strong>Feb. 5 </strong>“We had 109 people out  ...\n",
              "[16] <span class=\"short-desc\"><strong>Feb. 6 </strong>“I have already saved m ...\n",
              "[17] <span class=\"short-desc\"><strong>Feb. 6 </strong>“It's gotten to a point ...\n",
              "[18] <span class=\"short-desc\"><strong>Feb. 6 </strong>“The failing @nytimes w ...\n",
              "[19] <span class=\"short-desc\"><strong>Feb. 6 </strong>“And the previous admin ...\n",
              "[20] <span class=\"short-desc\"><strong>Feb. 7 </strong>“And yet the murder rat ...\n",
              "..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Jr9nmW5wIO",
        "colab_type": "text"
      },
      "source": [
        "Esto devuelve una lista con 116 nodos XML que contienen la información de cada una de las 116 mentiras de la página web.\n",
        "\n",
        "Fíjate que estoy usando el %>% pipe-operator del paquete magrittr, que puede ayudar a expresar operaciones complejas como elegantes tuberías compuestas de piezas simples y fáciles de entender.\n",
        "\n",
        "## Extrayendo la fecha\n",
        "\n",
        "Comencemos con algo simple y concentrémonos en extraer todos los detalles necesarios de la primera mentira. Luego podemos extender esto a todos los demás fácilmente. Recuerden que la estructura general para un solo registro es:\n",
        "\n",
        "<span class=\"short-desc\"><strong> FECHA </strong> MENTIRA <span class=\"short-truth\"><a href=\"URL\"> EXPLICACIÓN </a></span></span>\n",
        "\n",
        "Fíjese que la fecha está incrustada dentro de la etiqueta <strong>. Para seleccionarla, podemos usar la función html_nodes() usando el selector \"strong\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vxm6YAU51L6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5bc41fd3-652a-49da-f983-79c8dc8d5b5c"
      },
      "source": [
        "first_result <- results[1]\n",
        "first_result %>% html_nodes(\"strong\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{xml_nodeset (1)}\n",
              "[1] <strong>Jan. 21 </strong>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP_vvaSB50yC",
        "colab_type": "text"
      },
      "source": [
        "Entonces necesitamos usar la función html_text() para extraer sólo el texto, con el argumento trim activo para recortar los espacios anteriores y posteriores. Finalmente, utilizamos el paquete stringr para añadir el año a la fecha extraída."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebOBneFX57TV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "164d69bc-0169-484c-e694-685595ea7953"
      },
      "source": [
        "first_result <- results[1]\n",
        "date <- first_result %>% html_nodes(\"strong\") %>% html_text(trim = TRUE)\n",
        "\n",
        "library(stringr)\n",
        "str_c(date, ', 2017')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"Jan. 21, 2017\""
            ],
            "text/latex": "'Jan. 21, 2017'",
            "text/markdown": "'Jan. 21, 2017'",
            "text/html": [
              "'Jan. 21, 2017'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZLv1Uh76G_W",
        "colab_type": "text"
      },
      "source": [
        "# Extrayendo la mentira\n",
        "\n",
        "Para seleccionar la mentira, necesitamos hacer uso de la función xml_contents() que forma parte del paquete xml2 (este paquete es requerido por el paquete rvest, por lo que no es necesario cargarlo). La función devuelve una lista con los nodos que forman parte de first_result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp5irmmP6Lhh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7d53ce7d-78b8-4524-8984-f1e3fc17aa25"
      },
      "source": [
        "xml_contents(first_result)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{xml_nodeset (3)}\n",
              "[1] <strong>Jan. 21 </strong>\n",
              "[2] “I wasn't a fan of Iraq. I didn't want to go into Iraq.” \n",
              "[3] <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczyns ..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amw2lgAm6Nsv",
        "colab_type": "text"
      },
      "source": [
        "Fíjese que hay un par de citas extra (\"...\") que rodean la mentira. Para deshacernos de ellas, simplemente usamos la función str_sub() del paquete stringr para seleccionar sólo la mentira."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4S1bPcH6SB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cb42ab7-b801-45b6-ba5c-b152cdcd2aa1"
      },
      "source": [
        "lie <- xml_contents(first_result)[2] %>% html_text(trim = TRUE)\n",
        "str_sub(lie, 2, -2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"I wasn't a fan of Iraq. I didn't want to go into Iraq.\""
            ],
            "text/latex": "'I wasn\\textbackslash{}'t a fan of Iraq. I didn\\textbackslash{}'t want to go into Iraq.'",
            "text/markdown": "'I wasn\\'t a fan of Iraq. I didn\\'t want to go into Iraq.'",
            "text/html": [
              "'I wasn\\'t a fan of Iraq. I didn\\'t want to go into Iraq.'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4f5tRZe6VKn",
        "colab_type": "text"
      },
      "source": [
        "# Extrayendo la explicación\n",
        "\n",
        "Esperemos que a estas alturas no sea demasiado complicado ver que para extraer la explicación simplemente tenemos que seleccionar el texto dentro de la etiqueta <span> que pertenece a class=\".short-truth\". Esto extraerá el texto junto con los paréntesis de apertura y cierre, pero podemos deshacernos de ellos fácilmente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLNP_dHc6d7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfbc79c9-7ad5-4779-ac73-83624630d253"
      },
      "source": [
        "explanation <- first_result %>% html_node(\".short-truth\") %>% html_text(trim = TRUE)\n",
        "str_sub(explanation, 2, -2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"He was for an invasion before he was against it.\""
            ],
            "text/latex": "'He was for an invasion before he was against it.'",
            "text/markdown": "'He was for an invasion before he was against it.'",
            "text/html": [
              "'He was for an invasion before he was against it.'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl-fW52s6mA9",
        "colab_type": "text"
      },
      "source": [
        "## Extrayendo el URL\n",
        "\n",
        "Por último, para obtener la URL, noten que es un atributo dentro de la etiqueta <a>. Simplemente seleccionamos este nodo con la función html_nodes(), y luego seleccionamos el atributo href con la función html_attr()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyjJgQkj6lhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "408ed3a9-5081-422e-f2f1-f691cbf9bec5"
      },
      "source": [
        "url <- first_result %>% html_node(\"a\") %>% html_attr(\"href\")\n",
        "url"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\""
            ],
            "text/latex": "'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the'",
            "text/markdown": "'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the'",
            "text/html": [
              "'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXEH0yQ56xYc",
        "colab_type": "text"
      },
      "source": [
        "## Construir el conjunto de datos\n",
        "\n",
        "Encontramos una forma de extraer cada una de las 4 partes del primer registro. Podemos extender este proceso a todos los demás usando un bucle de for. Al final, queremos tener un marco de datos con 116 filas (una para cada registro) y 4 columnas (para mantener la fecha, la mentira, la explicación y la URL). Una forma de hacerlo es crear un marco de datos vacío y simplemente añadir una nueva fila a medida que se procesa cada nuevo registro. Sin embargo, esto no se considera una buena práctica. Como se sugiere aquí, vamos a crear un solo marco de datos para cada registro y almacenarlos todos en una lista. Una vez que tengamos los 116 marcos de datos, los uniremos usando la función bind_rows() del paquete dplyr. Esto crea nuestro conjunto de datos deseado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sDfIdqe6ycu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "e234c202-33eb-402c-88c5-13730075ffeb"
      },
      "source": [
        "library(dplyr)\n",
        "records <- vector(\"list\", length = length(results))\n",
        "\n",
        "for (i in seq_along(results)) {\n",
        "    date <- str_c(results[i] %>% html_nodes(\"strong\") %>% html_text(trim = TRUE), \", 2017\")\n",
        "    lie <- str_sub(xml_contents(results[i])[2] %>% html_text(trim = TRUE), 2, -2)\n",
        "    explanation <- str_sub(results[i] %>% html_nodes(\".short-truth\") %>% html_text(trim = TRUE), 2, -2)\n",
        "    url <- results[i] %>% html_nodes(\"a\") %>% html_attr(\"href\")\n",
        "    records[[i]] <- data_frame(date = date, lie = lie, explanation = explanation, url = url)\n",
        "}\n",
        "\n",
        "df <- bind_rows(records)\n",
        "glimpse(df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n",
            "Warning message:\n",
            "“`data_frame()` is deprecated as of tibble 1.1.0.\n",
            "Please use `tibble()` instead.\n",
            "\u001b[90mThis warning is displayed once every 8 hours.\u001b[39m\n",
            "\u001b[90mCall `lifecycle::last_warnings()` to see where this warning was generated.\u001b[39m”\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Rows: 180\n",
            "Columns: 4\n",
            "$ date        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Jan. 21, 2017\", \"Jan. 21, 2017\", \"Jan. 23, 2017\", \"Jan. …\n",
            "$ lie         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"I wasn't a fan of Iraq. I didn't want to go into Iraq.\",…\n",
            "$ explanation \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"He was for an invasion before he was against it.\", \"Trum…\n",
            "$ url         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-…\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaKhGQIC6_S0",
        "colab_type": "text"
      },
      "source": [
        "Obsérvese que la columna de la fecha se considera un vector de carácter. Sería bueno tenerla como un vector de fecha y hora en su lugar. Para ello, podemos usar el paquete de lubridate y usar la función mdy() (mes-día-año) para hacer la conversión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG32fZxn7Fxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "09577209-e5cd-43e8-a968-206bdbcc7ed9"
      },
      "source": [
        "library(lubridate)\n",
        "df$date <- mdy(df$date)\n",
        "glimpse(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Attaching package: ‘lubridate’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    date, intersect, setdiff, union\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Rows: 180\n",
            "Columns: 4\n",
            "$ date        \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m 2017-01-21, 2017-01-21, 2017-01-23, 2017-01-25, 2017-01-…\n",
            "$ lie         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"I wasn't a fan of Iraq. I didn't want to go into Iraq.\",…\n",
            "$ explanation \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"He was for an invasion before he was against it.\", \"Trum…\n",
            "$ url         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-…\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcOTa-Jn7L37",
        "colab_type": "text"
      },
      "source": [
        "Exportar el conjunto de datos a un archivo CSV\n",
        "\n",
        "Si quieres exportar tu conjunto de datos, puedes usar la función write.csv() que viene por defecto con R, o la función write_csv() del paquete readr, que es dos veces más rápida y conveniente que la primera."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpOmStyb7Mty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "readr::write_csv(df, \"trump_lies.csv\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0lp1J__7ca_",
        "colab_type": "text"
      },
      "source": [
        "Del mismo modo, para recuperar su conjunto de datos, puede utilizar la función predeterminada read.csv() o la función read_csv() del paquete readr."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TvTasSV7dX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a923d975-c7c2-4c35-c3da-4f9f746459d3"
      },
      "source": [
        "df <- readr::read_csv(\"trump_lies.csv\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsed with column specification:\n",
            "cols(\n",
            "  date = \u001b[34mcol_date(format = \"\")\u001b[39m,\n",
            "  lie = \u001b[31mcol_character()\u001b[39m,\n",
            "  explanation = \u001b[31mcol_character()\u001b[39m,\n",
            "  url = \u001b[31mcol_character()\u001b[39m\n",
            ")\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vml2em4n7mhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "33c632fc-1864-40b7-9f30-3a00617d585a"
      },
      "source": [
        "head(df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  date      \n",
              "1 2017-01-21\n",
              "2 2017-01-21\n",
              "3 2017-01-23\n",
              "4 2017-01-25\n",
              "5 2017-01-25\n",
              "6 2017-01-25\n",
              "  lie                                                                                                                                               \n",
              "1 I wasn't a fan of Iraq. I didn't want to go into Iraq.                                                                                            \n",
              "2 A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.\n",
              "3 Between 3 million and 5 million illegal votes caused me to lose the popular vote.                                                                 \n",
              "4 Now, the audience was the biggest ever. But this crowd was massive. Look how far back it goes. This crowd was massive.                            \n",
              "5 Take a look at the Pew reports (which show voter fraud.)                                                                                          \n",
              "6 You had millions of people that now aren't insured anymore.                                                                                       \n",
              "  explanation                                                                          \n",
              "1 He was for an invasion before he was against it.                                     \n",
              "2 Trump was on the cover 11 times and Nixon appeared 55 times.                         \n",
              "3 There's no evidence of illegal voting.                                               \n",
              "4 Official aerial photos show Obama's 2009 inauguration was much more heavily attended.\n",
              "5 The report never mentioned voter fraud.                                              \n",
              "6 The real number is less than 1 million, according to the Urban Institute.            \n",
              "  url                                                                                                   \n",
              "1 https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the  \n",
              "2 http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/                                \n",
              "3 https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html                   \n",
              "4 https://www.nytimes.com/2017/01/21/us/politics/trump-white-house-briefing-inauguration-crowd-size.html\n",
              "5 https://www.nytimes.com/2017/01/24/us/politics/unauthorized-immigrant-voting-trump-lie.html           \n",
              "6 https://www.nytimes.com/2017/03/13/us/politics/fact-check-trump-obamacare-health-care.html            "
            ],
            "text/latex": "A tibble: 6 × 4\n\\begin{tabular}{llll}\n date & lie & explanation & url\\\\\n <date> & <chr> & <chr> & <chr>\\\\\n\\hline\n\t 2017-01-21 & I wasn't a fan of Iraq. I didn't want to go into Iraq.                                                                                             & He was for an invasion before he was against it.                                      & https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the  \\\\\n\t 2017-01-21 & A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine. & Trump was on the cover 11 times and Nixon appeared 55 times.                          & http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/                                \\\\\n\t 2017-01-23 & Between 3 million and 5 million illegal votes caused me to lose the popular vote.                                                                  & There's no evidence of illegal voting.                                                & https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html                   \\\\\n\t 2017-01-25 & Now, the audience was the biggest ever. But this crowd was massive. Look how far back it goes. This crowd was massive.                             & Official aerial photos show Obama's 2009 inauguration was much more heavily attended. & https://www.nytimes.com/2017/01/21/us/politics/trump-white-house-briefing-inauguration-crowd-size.html\\\\\n\t 2017-01-25 & Take a look at the Pew reports (which show voter fraud.)                                                                                           & The report never mentioned voter fraud.                                               & https://www.nytimes.com/2017/01/24/us/politics/unauthorized-immigrant-voting-trump-lie.html           \\\\\n\t 2017-01-25 & You had millions of people that now aren't insured anymore.                                                                                        & The real number is less than 1 million, according to the Urban Institute.             & https://www.nytimes.com/2017/03/13/us/politics/fact-check-trump-obamacare-health-care.html            \\\\\n\\end{tabular}\n",
            "text/markdown": "\nA tibble: 6 × 4\n\n| date &lt;date&gt; | lie &lt;chr&gt; | explanation &lt;chr&gt; | url &lt;chr&gt; |\n|---|---|---|---|\n| 2017-01-21 | I wasn't a fan of Iraq. I didn't want to go into Iraq.                                                                                             | He was for an invasion before he was against it.                                      | https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the   |\n| 2017-01-21 | A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine. | Trump was on the cover 11 times and Nixon appeared 55 times.                          | http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/                                 |\n| 2017-01-23 | Between 3 million and 5 million illegal votes caused me to lose the popular vote.                                                                  | There's no evidence of illegal voting.                                                | https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html                    |\n| 2017-01-25 | Now, the audience was the biggest ever. But this crowd was massive. Look how far back it goes. This crowd was massive.                             | Official aerial photos show Obama's 2009 inauguration was much more heavily attended. | https://www.nytimes.com/2017/01/21/us/politics/trump-white-house-briefing-inauguration-crowd-size.html |\n| 2017-01-25 | Take a look at the Pew reports (which show voter fraud.)                                                                                           | The report never mentioned voter fraud.                                               | https://www.nytimes.com/2017/01/24/us/politics/unauthorized-immigrant-voting-trump-lie.html            |\n| 2017-01-25 | You had millions of people that now aren't insured anymore.                                                                                        | The real number is less than 1 million, according to the Urban Institute.             | https://www.nytimes.com/2017/03/13/us/politics/fact-check-trump-obamacare-health-care.html             |\n\n",
            "text/html": [
              "<table>\n",
              "<caption>A tibble: 6 × 4</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>date</th><th scope=col>lie</th><th scope=col>explanation</th><th scope=col>url</th></tr>\n",
              "\t<tr><th scope=col>&lt;date&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>2017-01-21</td><td>I wasn't a fan of Iraq. I didn't want to go into Iraq.                                                                                            </td><td>He was for an invasion before he was against it.                                     </td><td>https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the  </td></tr>\n",
              "\t<tr><td>2017-01-21</td><td>A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.</td><td>Trump was on the cover 11 times and Nixon appeared 55 times.                         </td><td>http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/                                </td></tr>\n",
              "\t<tr><td>2017-01-23</td><td>Between 3 million and 5 million illegal votes caused me to lose the popular vote.                                                                 </td><td>There's no evidence of illegal voting.                                               </td><td>https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html                   </td></tr>\n",
              "\t<tr><td>2017-01-25</td><td>Now, the audience was the biggest ever. But this crowd was massive. Look how far back it goes. This crowd was massive.                            </td><td>Official aerial photos show Obama's 2009 inauguration was much more heavily attended.</td><td>https://www.nytimes.com/2017/01/21/us/politics/trump-white-house-briefing-inauguration-crowd-size.html</td></tr>\n",
              "\t<tr><td>2017-01-25</td><td>Take a look at the Pew reports (which show voter fraud.)                                                                                          </td><td>The report never mentioned voter fraud.                                              </td><td>https://www.nytimes.com/2017/01/24/us/politics/unauthorized-immigrant-voting-trump-lie.html           </td></tr>\n",
              "\t<tr><td>2017-01-25</td><td>You had millions of people that now aren't insured anymore.                                                                                       </td><td>The real number is less than 1 million, according to the Urban Institute.            </td><td>https://www.nytimes.com/2017/03/13/us/politics/fact-check-trump-obamacare-health-care.html            </td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_5_5TPF8L6q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Resumen\n",
        "\n",
        "A continuación se muestra el código completo de este tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH8oAg-r8SB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load packages\n",
        "library(rvest)\n",
        "library(stringr)\n",
        "library(dplyr)\n",
        "library(lubridate)\n",
        "library(readr)\n",
        "\n",
        "# Read web page\n",
        "webpage <- read_html(\"https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html\")\n",
        "\n",
        "# Extract records info\n",
        "results <- webpage %>% html_nodes(\".short-desc\")\n",
        "\n",
        "# Building the dataset\n",
        "records <- vector(\"list\", length = length(results))\n",
        "\n",
        "for (i in seq_along(results)) {\n",
        "    date <- str_c(results[i] %>% \n",
        "                      html_nodes(\"strong\") %>% \n",
        "                      html_text(trim = TRUE), ', 2017')\n",
        "    lie <- str_sub(xml_contents(results[i])[2] %>% html_text(trim = TRUE), 2, -2)\n",
        "    explanation <- str_sub(results[i] %>% \n",
        "                               html_nodes(\".short-truth\") %>% \n",
        "                               html_text(trim = TRUE), 2, -2)\n",
        "    url <- results[i] %>% html_nodes(\"a\") %>% html_attr(\"href\")\n",
        "    records[[i]] <- data_frame(date = date, lie = lie, explanation = explanation, url = url)\n",
        "}\n",
        "\n",
        "df <- bind_rows(records)\n",
        "\n",
        "# Transform to datetime format\n",
        "df$date <- mdy(df$date)\n",
        "\n",
        "# Export to csv\n",
        "write_csv(df, \"trump_lies.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3uXKhzi7-Bw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "También quiero mencionar que los paquetes de stringr, dplyr, lubricante y readr son todos parte de la familia tidyverse. Esta es una colección de paquetes R que están diseñados para trabajar juntos para hacer el proceso de análisis de datos más fácil. De hecho, también podrías usar el popular paquete purrr para evitar el bucle for. Sin embargo, esto requeriría la creación de una función que mapee cada registro a un marco de datos. Para otro ejemplo de cómo hacer web scraping, mira esta impresionante entrada de blog de Dean Attali.\n",
        "\n",
        "Espero que encuentres este tutorial útil. Su propósito no es mostrar qué lenguaje de programación es mejor, sino aprender tanto de Python como de R, así como aumentar tus habilidades de programación y herramientas para abordar un conjunto más diverso de problemas.\n"
      ]
    }
  ]
}